\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath,amssymb,mathrsfs}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{parskip}
\usepackage[version=3]{mhchem} 
\usepackage{fixltx2e}
\usepackage{refcount}
\usepackage{siunitx}
\usepackage{lastpage}
\usepackage{textcomp}
\usepackage{xfrac}
\usepackage{lmodern}
\usepackage{cool}
\usepackage{cancel}
\usepackage{microtype}
\usepackage{gensymb}
\usepackage{enumerate}
\usepackage{float}
\usepackage{bm}
\usepackage{csquotes}
\usepackage{mathtools}
\usepackage{mcode}

\usepackage[hidelinks]{hyperref}

\DeclarePairedDelimiter\bra{\langle}{\rvert}
\DeclarePairedDelimiter\ket{\lvert}{\rangle}
\DeclarePairedDelimiterX\braket[2]{\langle}{\rangle}{#1 \delimsize\vert #2}








%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\clubpenalty = 10000
\widowpenalty = 10000

\pagestyle{fancy}
\lhead{\hmwkAuthorName}
\chead{\hmwkClass\ \textemdash\ \hmwkTitle}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{ASV\twodigits{\thepage}\ of \twodigits{\getpagerefnumber{LastPage}}}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}
\setlength\parskip{1.2ex}





%
% Create Problem Sections
%

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Problem \arabic{#1} continued on next 
page\ldots}\nobreak{}
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} 
continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} 
continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
    
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}

%
% Homework Problem Environment
%
% This environment takes an optional argument. When given, it will adjust the
% problem counter. This is useful for when the problems given for your
% assignment aren't sequential. See the last 3 problems of this template for an
% example.
%
\newenvironment{homeworkProblem}[1][-1]{
    \ifnum#1>0
	\setcounter{homeworkProblemCounter}{#1}
    \fi
%     \section{Problem \arabic{homeworkProblemCounter}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
    \pagebreak

}

%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Instructor
%   - Author
%

\newcommand{\hmwkTitle}{Homework\ \# 02}
\newcommand{\hmwkDueDate}{04 October 2016}
\newcommand{\hmwkClass}{NE 255}
\newcommand{\hmwkClassInstructor}{Professor Rachel Slaybaugh}
\newcommand{\hmwkAuthorName}{Andrew S Voyles}

%
% Title Page
%

\title{
%     \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \normalsize\vspace{0.1in}\small{Due\ \hmwkDueDate}\\
    \vspace{0.1in}\large{\textit{\hmwkClassInstructor}}
}

\author{\textbf{\hmwkAuthorName}}
\date{}

\renewcommand{\part}[1]{\textbf{\large Part 
\Alph{partCounter}}\stepcounter{partCounter}\\}

%
% Various Helper Commands
%

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\simplepderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}

% Alias for the Solution section header
\newcommand{\solution}{\textbf{\large Solution}}

% One sentence of lorem ipsum text
\newcommand{\shortlipsum}{Lorem ipsum dolor sit amet, consectetuer adipiscing 
elit.}

% Pad zeroes for footer numbering
\newcommand\twodigits[1]{%
  \ifnum#1<10 0#1\else #1\fi
}

% Consistant figure references
\newcommand{\figref}[1]{Figure~\ref{#1}}

% Define partial derivative alias
\newcommand{\partialder}[2]{\dfrac{\partial #1}{\partial #2}}

% Volume symbol
\newcommand{\volume}{\mathop{\ooalign{\hfil$V$\hfil\cr\kern0.08em--\hfil\cr}}\nolimits}

% Area symbol
\newcommand{\area}{\mathop{\ooalign{\hfil$A$\hfil\cr\kern0.08em--\hfil\cr}}\nolimits}

% Sin and Cos with auto-parentheses 
\newcommand{\sinp}[1]{\sin{\left( #1\right)}}
\newcommand{\cosp}[1]{\cos{\left( #1\right)}}
\newcommand{\expp}[1]{\exp{\left( #1\right)}}
\newcommand{\sinhp}[1]{\sinh{\left( #1\right)}}
\newcommand{\lnp}[1]{\ln{\left( #1\right)}}
\newcommand{\pp}[1]{\left( #1\right)}
\newcommand{\sci}[2]{ #1 \cdot 10^{#2}\ }
\newcommand{\angstrom}{\mbox{\normalfont\AA}}
\newcommand{\norm}[1]{\lVert #1 \rVert}






% math syntax
\newcommand{\nth}{n\ensuremath{^{\text{th}}} }
\newcommand{\ve}[1]{\ensuremath{\mathbf{#1}}}
\newcommand{\Macro}{\ensuremath{\Sigma}}
\newcommand{\rvec}{\ensuremath{\vec{r}}}
\newcommand{\xvec}{\ensuremath{\vec{x}}}
\newcommand{\omvec}{\ensuremath{\hat{\Omega}}}
\newcommand{\vOmega}{\ensuremath{\hat{\Omega}}}


% Make vectors use boldface
\renewcommand{\vec}[1]{\mathbf{#1}}


% Consistant matrix notation
\newcommand{\matr}[1]{\mathbf{#1}} % undergraduate algebra version
% \newcommand{\matr}[1]{#1}          % pure math version
% \newcommand{\matr}[1]{\boldsymbol{#1}}     % ISO complying version


\makeatletter
% Make common definition of mean
\newcommand*\mean[1]{\overline{#1\raisebox{3mm}{}}}

\makeatother






\begin{document}

\maketitle
\thispagestyle{fancy}





\section{Problem 1}

\begin{homeworkProblem}

 Derive the 1st order form of $SP_5$ with isotropic source and vacuum boundary
conditions.




\subsection{Solution}
    
 XXXXXXXXXXXXXXXXXX
    

\end{homeworkProblem}


\section{Problem 2}

\begin{homeworkProblem}

Consider the integral

\begin{equation}
\int_{4\pi} d\omvec \left|\omvec\right|
\end{equation}

The LQ$_N$ quadrature set is given in XXX. Recall that $\mu_i = \eta_i = \xi_i$ for a given level, $i$.

\begin{figure}[H]
 \centering
 \includegraphics{./homework3-cropped.pdf}
 % homework3-cropped.pdf: 252x337 pixel, 72dpi, 8.89x11.89 cm, bb=0 0 252 337
 \caption{LQ$_n$ quadrature}
 \label{fig:LQquad}
\end{figure}


\begin{enumerate}[(a)] 

\item  Look up the Top 10 supercomputing list and briefly describe the architecture
of the top three machines. List the number of machines of each type on the
top 10 (e.g. X are GPU-accelerated, Y contain MICs, etc.)





\subsection{Solution}
    
  According to the Top500 project\footnote{\url{https://www.top500.org/}}, the top three machines (ranked in terms of peak achieved floating-point-operations per second, FLOPS) are the Sunway TaihuLight, the TH-2, and Titan:
  
  The Sunway TaihuLight is at the \#1 spot on the Top500 list, and is a  93 PFLOP supercomputer in Wuxi, China, which first came online in June 2016. It uses 40,960 SW26010 processors clocked at 1.45 GHz, each of which contains 256 processing cores, for a total of 10,649,600 cores across the cluster. These are custom many-core processors using the RISC architecture, which eschews  typical cache structure for inter-core communication for a dedicated network between core clusters, which greatly improves the parallel efficiency of the cores. The machine is supported by 1.3 PBytes of RAM, and consumes approximately 15 MW of power. The machine runs on Sunway RaiseOS, a custom high-performance computing Linux distribution.  
  
  The Tianhe-2 is at the \#2 spot on the Top500 list, and is a  34 PFLOP supercomputer in Guangzhou, China, which first came online in June 2013. It uses 16,000 computing nodes, each of which contains two Intel Xeon E5-2692 12-core CPUs running at 2.2 GHz supported by 64 GB of RAM, and three Xeon Phi 31S1P co-processors, which contain 57 cores running at 1.1 GHz, supported by 8 GB of RAM. This is a combined 3,120,000 processing cores and 1.34 PBytes of RAM across the system, which consumes 17.6 MW of power.  The machine runs on Kylin, a custom high-performance computing Linux distribution.  
  
   Titan is at the \#3 spot on the Top500 list, and is a  17 PFLOP supercomputer Oak Ridge National Lab, in Oak Ridge, Tennessee, which first came online in October 2012. It uses 18,688 computing nodes, each of which contains one AMD Opteron 6274 16-core CPU running at 2.2 GHz supported by 32 GB of RAM, and one  Nvidia Tesla K20X GPU, which contains 2688 CUDA cores running at 732 MHz, supported by 6 GB of RAM. This is a combined 50,532,352 processing cores and 694 TBytes of RAM across the system, which consumes 8.2 MW of power.
   
   In this top 10 list, 6 computers (Sunway TaihuLight, Sequoia, Mira, Trinity, Hazel Hen, Shaheen II)  use massively multi-core custom primary CPUs as an architecture, 2 computers (Titan, Piz Daint) are GPU-accelerated,  1 computer (Tianhe-2 ) uses MICs / co-processors, and 1 computer (K-Computer) uses an alternative customs CPU architectures. 
 
   
\item   Describe the main characteristics of GPUs, MICs (multi integrated
cores), and CPUs-memory, clock speed, structure, etc.




\subsection{Solution}
    
   The CPU is the heart of a computer, the primary integrated circuit responsible for computation. The CPU receives instructions from some compiled binary code, decodes these instructions into a series of electrical commands, and then electrically connects its internal transistors, to perform the requested computation or operation.  CPUs have small memory buffers called \emph{caches}, which are responsible for holding commands, outputs, and memory addresses, as well as facilitating data I/O between the CPU and the motherboard, which have sizes on the order of a few MB in modern CPUs.
   
   The commands read and executed by a CPU are measured in \emph{clock cycles}, a unit of time used to regulate the operation of the CPU. Clock cycles can be used to measure the time required to complete the electrical operation involved in reading in binary instructions, decoding them, and executing the requested operation. Each operation consists of multiple instruction signals, so the more clock cycles that a CPU can execute per unit time, the more operations it is capable of performing per unit time. Clock speed, the number of clock cycles per second, is measured in Hz, and is a common measure of the internal processing speed of a CPU.
   
   A co-processor or multi-integrated core (MIC) is a sort of secondary processor, which is always paired with at least one primary CPU in a computing node. This design greatly accelerates computation by offloading intense and parallelizable sections of computation from the primary CPUs (which are optimized for several large serial tasks, due to their high clock speed) to the multiple cores in the co-processor, each of which are optimized for small, independent tasks, due to their lower clock speed. This allows a MIC to split a long serial computation into a very short parallel operation, assuming that the code is capable of being translated into an algorithm supporting parallel operation, such as finite element analysis.
   
   A GPU (graphical processing unit) is another type of processor, very similar in design to a MIC. Like a MIC, GPUs are processors comprised of hundreds to thousands of slower-clock speed cores, each of which has its own memory buffer. Traditionally, GPUs are used generate computer images and video, a process which is extremely demanding on the CPU. By moving these processes to a separate processor, the GPU, the CPU is freed up to focus on more intensive serial operations. Since the process of rendering these graphics is a naturally parallel task, the many small GPU cores turn a very CPU-intensive process into a much more trivial parallel task. To handle all of the data used during these parallel tasks, most modern GPUs have their own dedicated memory, on the order of several to tens of GB.
   
   \item Based on what we've talked about so far, postulate challenges of solving
the neutron transport equation in a way that would work on all of these architectures.



\subsection{Solution}
    
   We have discussed the two primary computational solution methods: deterministic methods, which discretize a large problem into multiple small elements, each of which is solved analytically. These problems are often hard to perform in parallel, but are well-suited to solution using many high-clock speed CPUs, and are easily executed on multi-core supercomputers. Due to the nature of matrix diagonalization, many of these finite-element methods are now being ported to parallel computation, however.
   
   Monte Carlo methods, on the other hand, use random sampling of events in a probability distribution to look at aggregate behavior of systems. In neutron transport, we can simulate the lifetime and interactions of a single neutron as it is transported through a volume. By performing this for many (\(\gg 10^8\)) neutrons, we can solve the NTE for neutron fluxes in various volumes by building up a statistically significant number of particle histories. Since each particle is transported independently, these Monte Carlo problems are very well-suited to parallel computation, and are frequently  performed on MIC and GPU-accelerated machines.


\end{enumerate}

\end{homeworkProblem}


\section{Problem 3}

\begin{homeworkProblem}

We often measure convergence by comparing one iteration to the previous
iteration (rather than the solution, since we presumably don't know what it is). Imagine
that you have software that gives the following solution vectors:

% \begin{figure}[H]
%  \centering
%  \includegraphics{./hw02_03a.pdf}
%  % hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
% \end{figure}


Calculate:




\begin{enumerate}[(a)] 

\item The absolute and relative error using the 1 norm.




\subsection{Solution}

For some vector \xvec, the \(\ell_1\) norm is calculated as:

\begin{equation}
 \norm{ \xvec }_1 = \sum_{i=1}^N \left| x_i \right|
\end{equation}

For some norm \(\norm{\cdot}\), we will define the absolute error between solution vectors \(x_n\) and \(x_{n-1}\) as:

\begin{equation}
\epsilon_A = \norm{x_n-x_{n-1}}
\end{equation}

Similarly, the relative error is:

\begin{equation}
\epsilon_R = \dfrac{ \norm{x_n-x_{n-1}}}{ \norm{x_n}} = \dfrac{ \epsilon_A}{ \norm{x_n}}
\end{equation}

Using these definitions and the  \(\ell_1\) norm:

\begin{equation}
\epsilon_A = \sum \pp{0.05, 0.05, 0.1, 0.05, 0.1  }^T = 0.35
\end{equation}

\begin{equation}
\epsilon_R = \dfrac{0.35}{ \sum \pp{0.5, 0.9, 0.3, 0.1, 0.5  }^T} = 0.1522
\end{equation}
 
   
\item   The absolute and relative error using the 2 norm




\subsection{Solution}

   
For some vector \xvec, the \(\ell_2\) norm is calculated as:

\begin{equation}
 \norm{ \xvec }_2 = \sqrt{\sum_{i=1}^N  x_i^2  }
\end{equation}
   
   
   
Using these definitions:

\begin{equation}
\epsilon_A = \sqrt{\sum \pp{0.0025, 0.0025, 0.01, 0.0025, 0.01 }^T} = 0.1658
\end{equation}

\begin{equation}
\epsilon_R = \dfrac{0.1658}{\sqrt{\sum \pp{0.25, 0.81, 0.09, 0.01, 0.25 }^T}} = 0.1397
\end{equation}
   
   
\item The absolute and relative error using the infinity norm.

What is most restrictive (that is, what would cause the code to converge first)?

Image that now \(x_{n-1} = (0.49, 0.92, 0.4, -0.09, 0.51)^T\). Recalculate the convergence values.

What do you observe? What does that mean about how you might select convergence
criteria?




\subsection{Solution}

  
For some vector \xvec, the \(\ell_\infty\) norm is calculated as:

\begin{equation}
 \norm{ \xvec }_\infty = \max_{1 \leq i \leq N} \left| x_i \right|
\end{equation}
   
   
   
Using these definitions:

\begin{equation}
\epsilon_A = \max \pp{0.05, 0.05, 0.1, 0.05, 0.1 }^T = 0.1
\end{equation}

\begin{equation}
\epsilon_R = \dfrac{0.1}{\max \pp{0.5, 0.9, 0.3, 0.1, 0.5  }^T} = 0.111
\end{equation}
   
   
\begin{table}[H]
\centering
\caption{Tabulated results for the various error criteria.}
\label{tab:firstx}
\begin{tabular}{c|c|c}
 Norm    & \(\epsilon_A\)     & \(\epsilon_R\)     \\ \hline
\(\ell_1\)   & 0.35   & 0.1522 \\
\(\ell_2\)   & 0.1658 & 0.1397 \\
\(\ell_\infty\) & 0.1    & 0.1111
\end{tabular}
\end{table}   

These results can be seen tabulated in \autoref{tab:firstx}. For most iterative methods, when the true solution is unknown, iteration continues until the error between two subsequent iterations falls below a set threshold. This leaves us with two ways to interpret convergence speed in the context of this problem. Since the \(\ell_\infty\) norm has the smallest of both the absolute and relative errors, it would predict that the two solution vectors are the closest to convergence, i.e., it would be the first to converge starting at the current timestep, assuming that the iterative method employed has monotonically decreasing errors between iterations. A second interpretation would be to look at the \(\ell_1\) norm, which has the largest of  both the absolute and relative errors. Many iterative solvers would see this as being \enquote{far} away from convergence, and take either a larger time step, or iterate more aggressively towards the solution, potentially reaching convergence first, at the risk of overshooting due to the \enquote{bang-bang} nature of aggressive iteration.

Repeating our analysis for the second \(x_{n-1}\) vector (with calculations not listed here for clarity, but verified in the \texttt{hw02\_03.m} script included in the parent repo), we see the results tabulated in \autoref{tab:firstx2}. Through inspection of these results, we that while the absolute errors have decreased in magnitude somewhat significantly from before, the relative errors have decreased by a smaller magnitude. Since the new \(x_{n-1}\) vector was closer to \(x_n\) than the old \(x_{n-1}\) vector, this illustrates why relative errors are typically used as convergence tolerances, as they normalize the scale of an error to its nominal value. 

It is also very important to point out that the \(\ell_\infty\) norms do not change at all for our new \(x_{n-1}\) vector. This is because , unlike the \(\ell_1\) and \(\ell_2\)  norms which look at the contributions of all errors between a pair of solution vectors, the \(\ell_\infty\)  only looks at the magnitude of the largest error contribution. While this can provide some stability against overshoot/undershoot by only focusing on minimizing the most significant error, it  ignores changes in the larger solution space, which can be used to give more feedback about one's proximity to convergence.

\begin{table}[H]
\centering
\caption{Tabulated results for the various error criteria, using the new \(x_{n-1}\).}
\label{tab:firstx2}
\begin{tabular}{c|c|c}
 Norm    & \(\epsilon_A\)     & \(\epsilon_R\)     \\ \hline
\(\ell_1\)   & 0.15   & 0.0652 \\
\(\ell_2\)   & 0.1034 & 0.0871 \\
\(\ell_\infty\) & 0.1    & 0.1111
\end{tabular}
\end{table}   
   

\end{enumerate}

\end{homeworkProblem}



\section{Problem 4}

\begin{homeworkProblem}

Write a function that generates the associated Legendre Polynomials:

\begin{equation}
P_\ell^m\pp{x} = \dfrac{\pp{-1}^m}{2^\ell \ell!} \pp{1-x^2}^{m/2} \dfrac{d^{\ell+m}}{dx^{\ell+m}} \pp{x^2-1}^\ell
\end{equation}

Use this function in a function that generates spherical harmonics:

\begin{equation}
Y_{\ell m} \pp{\theta,\phi} = \pp{-1}^m \sqrt{\dfrac{2\ell+m}{4\pi} \dfrac{\pp{\ell-m}!}{\pp{\ell+m}!}} P_{\ell m}\pp{\cosp{\theta}} e^{i m \phi} 
\end{equation}



\begin{enumerate}[(a)] 

\item  (30 points) Generate and plot the following $\ell$ = 0, 1, 2 for $-\ell \leq m \leq \ell$ (recall we
can relate the negate $m$ to positive $m$ values). You will need to discretize $\theta$ and $\phi$
fairly finely (I suggest 30 increments in each to start so you get a real sense of the
shape of the harmonics).




\subsection{Solution}
    
XXXXXXXXXXXXXXXXXX

   
   
\item   Now, we will approximate the external source. Using the $S_4$ quadrature
to do the integrations and $q_e$ = 1 for all angles: use the equations for external source
we developed in class (eqns. 19-21), calculate the external source for $\ell$ = 0, 1, 2.


\subsection{Solution}
    
   XXXXXXXXXXXXXXXXXXXXX
   
\begin{figure}[H]
\centering
\includegraphics{./Y00.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y00}
\label{fig:Y00}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{./Y11.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y11}
\label{fig:Y11}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{./Y10.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y10}
\label{fig:Y10}
\end{figure}



\begin{figure}[H]
\centering
\includegraphics{./Y1-1.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y1-1}
\label{fig:Y1-1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{./Y22.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y22}
\label{fig:Y22}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{./Y21.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y21}
\label{fig:Y21}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{./Y20.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y20}
\label{fig:Y20}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{./Y2-1.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y2-1}
\label{fig:Y2-1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics{./Y2-2.png}
% hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
 \caption{Y2-2}
\label{fig:Y2-2}
\end{figure}




    \end{enumerate}
    
 

\end{homeworkProblem}




\section{Problem 5}

\begin{homeworkProblem}

Consider the transport equation: 

\begin{align}
&\underbrace{\frac{1}{v}\frac{\partial \psi}{\partial t}(\rvec,E,\omvec,t)}_{\text{A}} + \underbrace{\omvec\cdot  \nabla \psi(\rvec,E,\omvec,t)}_{\text{B}} + \underbrace{\Sigma_t(\rvec,E)\psi(\rvec,E,\omvec,t) }_{\text{C}} = \underbrace{S(\rvec, E, \omvec,t)}_{\text{D}} \nonumber.
\\& \quad\quad\quad\quad  \underbrace{\int_0^{\infty}\int_{4\pi}\Sigma_s(\rvec, E'\rightarrow E,\omvec'\rightarrow\omvec) \psi(\rvec,E',\omvec',t)d\omvec'dE'}_{\text{E}}\nonumber
\\&\quad\quad\quad\quad\quad\quad +\underbrace{\frac{\chi_p(E)}{4\pi}\int_0^{\infty}\int_{4\pi}\nu(E')\Sigma_f(\rvec,E') \psi(\rvec,E',\omvec',t)d\omvec'dE'}_{\text{F}}\nonumber
\\&\quad\quad\quad\quad\quad\quad\quad\quad
\end{align}




\begin{enumerate}[(a)] 

\item  Briefly describe what each term in the Transport Equation physically
represents.




\subsection{Solution}
    
   
\begin{enumerate}[A)] 

\item Time rate of change of the neutron angular flux, the change in the neutron angular flux for an energy group  over the entire volume, as a function of time.. 

\item Streaming losses, the rate at which neutrons exit the control volume.

\item Total interaction losses, the rate at which neutrons are absorbed or outscattered from an energy and solid angle group.

\item External source gains, the rate at which neutrons enter the system, or from a generic point/line/distributed/etc source (other than fission) in the system.

\item Inscattering source gains, the rate at which neutrons are scattered into an energy and solid angle group.

\item Fission source gain, the rate at which neutrons are born through fission, into a particular energy group.


\end{enumerate}

   
   
\item   Rewrite the time independent form of the equation to include azimuthal
symmetry. Show the steps needed to get there.


\subsection{Solution}
    
   The first step is to make the time-independent assumption:
   
   \begin{equation}
\pderiv{\psi}{t} = 0
\end{equation}

This also removes all time dependence terms:
   
   
   \begin{equation}
\begin{split}
 \omvec\cdot  \nabla \psi(\rvec,E,\omvec) + \Sigma_t(\rvec,E)\psi(\rvec,E,\omvec)  &= S(\rvec, E, \omvec) 
\\
&+\int_0^{\infty}\int_{4\pi}\Sigma_s(\rvec, E'\rightarrow E,\omvec'\rightarrow\omvec) \psi(\rvec,E',\omvec')d\omvec'dE'
\\
& +\frac{\chi_p(E)}{4\pi}\int_0^{\infty}\int_{4\pi}\nu(E')\Sigma_f(\rvec,E') \psi(\rvec,E',\omvec')d\omvec'dE'
\end{split}
\end{equation}

 For the azimuthal symmetry assumption, scattering is only a function of \(\mu =\vOmega' \cdot \vOmega\), the cosine of the scattering angle. This gives us the  simplifications:
 
\(d\vOmega = \sin(\theta) d\theta d\varphi = d\mu d\varphi; \quad \mu = \cos(\theta);$  $d\mu = \sin(\theta)d\theta\:.\)
\begin{align}
\int_{4 \pi} d\vOmega &= \int_0^{2\pi} d\varphi \int_{-\pi/2}^{\pi/2} \sin(\theta) d\theta =  \int_0^{2\pi} d\varphi \int_{-1}^1 d\mu = 4\pi \\
\psi(\rvec,\vOmega,E) d\vOmega &= \psi(\rvec,\varphi, \mu,E) d\varphi  d\mu =  \psi(\rvec, \mu,E) d\varphi  d\mu 
\end{align}

The scattering cross section is no longer dependent on \(\varphi\):

\begin{equation}
\Sigma_s(\rvec, \vOmega' \rightarrow \vOmega) \rightarrow \Sigma_s(\rvec, \vOmega' \cdot \vOmega) = \Sigma_s(\rvec, \mu) 
\end{equation}



Thus,

\begin{equation}
\int_{4 \pi} d\vOmega\: \psi(\rvec, \vOmega, E) =   \int_0^{2\pi} d\varphi \int_{-1}^1 d\mu \:\psi(\rvec, \vOmega, E) = 2 \pi \int_{-1}^1 d\mu \:\psi(\rvec, \mu, E)
\end{equation}

Finally, the fission term can now be written in terms of the scalar flux:

\begin{equation}
\begin{split}
\frac{\chi_p(E)}{4\pi}\int_0^{\infty}\int_{4\pi}\nu(E')\Sigma_f(\rvec,E') \psi(\rvec,E',\omvec')d\omvec'dE' &=
 \frac{\chi_p(E)}{4\pi}\int_0^{\infty}\nu(E')\Sigma_f(\rvec,E') dE'  \int_{4\pi} \psi(\rvec,E',\omvec')d\omvec'
\\
&= \frac{\chi(E)}{2} \int_0^{\infty} dE'\:  \nu(E')\Sigma_f(\rvec,E')\phi(\rvec, E')
\end{split}
\end{equation}

Combining these all together:

 
   \begin{equation}
\begin{split}
 \mu\cdot  \nabla \psi(\rvec,E,\mu) + \Sigma_t(\rvec,E)\psi(\rvec,E,\mu)  &= S(\rvec, E, \mu) 
\\
&+ 2\pi\int_0^{\infty}dE' \int_{-1}^1\Sigma_s(\rvec, E'\rightarrow E,\mu') \psi(\rvec,E',\mu')d\mu'
\\
& +\frac{\chi(E)}{2} \int_0^{\infty} dE'\:  \nu(E')\Sigma_f(\rvec,E')\phi(\rvec, E')
\end{split}
\end{equation}


% \begin{figure}[H]
%  \centering
%  \includegraphics{./hw02_04a.pdf}
%  % hw02_03a.pdf: 204x92 pixel, 72dpi, 7.20x3.25 cm, bb=0 0 204 92
% \end{figure}
% 


    \end{enumerate}
    
 

\end{homeworkProblem}



\end{document}
